{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Загрузите данные об описаниях вакансий и соответствующих годовых зарплатах из файла salary-train.csv (либо его заархивированную версию salary-train.zip).\n",
    "\n",
    "2. Проведите предобработку:\n",
    "\n",
    "    * Приведите тексты к нижнему регистру (text.lower()).\n",
    "    \n",
    "    * Замените все, кроме букв и цифр, на пробелы — это облегчит дальнейшее разделение текста на слова. Для такой замены в строке text подходит следующий вызов: re.sub('[^a-zA-Z0-9]', ' ', text). Также можно воспользоваться методом replace у DataFrame, чтобы сразу преобразовать все тексты:\n",
    "    \n",
    "    * Примените TfidfVectorizer для преобразования текстов в векторы признаков. Оставьте только те слова, которые встречаются хотя бы в 5 объектах (параметр min_df у TfidfVectorizer).\n",
    "    * Замените пропуски в столбцах LocationNormalized и ContractTime на специальную строку 'nan'. Код для этого был приведен выше.\n",
    "    * Примените DictVectorizer для получения one-hot-кодирования признаков LocationNormalized и ContractTime.\n",
    "    * Объедините все полученные признаки в одну матрицу \"объекты-признаки\". Обратите внимание, что матрицы для текстов и категориальных признаков являются разреженными. Для объединения их столбцов нужно воспользоваться функцией scipy.sparse.hstack.\n",
    "\n",
    "\n",
    "3. Обучите гребневую регрессию с параметрами alpha=1 и random_state=241. Целевая переменная записана в столбце SalaryNormalized.\n",
    "\n",
    "\n",
    "4. Постройте прогнозы для двух примеров из файла salary-test-mini.csv. Значения полученных прогнозов являются ответом на задание. Укажите их через пробел."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Загрузите данные об описаниях вакансий и соответствующих годовых зарплатах из файла salary-train.csv (либо его заархивированную версию salary-train.zip)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FullDescription</th>\n",
       "      <th>LocationNormalized</th>\n",
       "      <th>ContractTime</th>\n",
       "      <th>SalaryNormalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>International Sales Manager London ****k  ****...</td>\n",
       "      <td>London</td>\n",
       "      <td>permanent</td>\n",
       "      <td>33000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>An ideal opportunity for an individual that ha...</td>\n",
       "      <td>London</td>\n",
       "      <td>permanent</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Online Content and Brand Manager// Luxury Reta...</td>\n",
       "      <td>South East London</td>\n",
       "      <td>permanent</td>\n",
       "      <td>40000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A great local marketleader is seeking a perman...</td>\n",
       "      <td>Dereham</td>\n",
       "      <td>permanent</td>\n",
       "      <td>22500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Registered Nurse / RGN  Nursing Home for Young...</td>\n",
       "      <td>Sutton Coldfield</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     FullDescription LocationNormalized  \\\n",
       "0  International Sales Manager London ****k  ****...             London   \n",
       "1  An ideal opportunity for an individual that ha...             London   \n",
       "2  Online Content and Brand Manager// Luxury Reta...  South East London   \n",
       "3  A great local marketleader is seeking a perman...            Dereham   \n",
       "4  Registered Nurse / RGN  Nursing Home for Young...   Sutton Coldfield   \n",
       "\n",
       "  ContractTime  SalaryNormalized  \n",
       "0    permanent             33000  \n",
       "1    permanent             50000  \n",
       "2    permanent             40000  \n",
       "3    permanent             22500  \n",
       "4          NaN             20355  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('salary-train.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Проведите предобработку:\n",
    "\n",
    "    * Приведите тексты к нижнему регистру (text.lower()).\n",
    "    \n",
    "    * Замените все, кроме букв и цифр, на пробелы — это облегчит дальнейшее разделение текста на слова. Для такой замены в строке text подходит следующий вызов: re.sub('[^a-zA-Z0-9]', ' ', text). Также можно воспользоваться методом replace у DataFrame, чтобы сразу преобразовать все тексты:\n",
    "    \n",
    "    * Примените TfidfVectorizer для преобразования текстов в векторы признаков. Оставьте только те слова, которые встречаются хотя бы в 5 объектах (параметр min_df у TfidfVectorizer).\n",
    "    * Замените пропуски в столбцах LocationNormalized и ContractTime на специальную строку 'nan'. Код для этого был приведен выше.\n",
    "    * Примените DictVectorizer для получения one-hot-кодирования признаков LocationNormalized и ContractTime.\n",
    "    * Объедините все полученные признаки в одну матрицу \"объекты-признаки\". Обратите внимание, что матрицы для текстов и категориальных признаков являются разреженными. Для объединения их столбцов нужно воспользоваться функцией scipy.sparse.hstack.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_transform(text: pd.Series) -> pd.Series:\n",
    "    return text.str.lower().replace(\"[^a-zA-Z0-9]\", \" \", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = TfidfVectorizer(min_df=5)\n",
    "X_train_text = vec.fit_transform(text_transform(df[\"FullDescription\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"LocationNormalized\"].fillna(\"nan\", inplace=True)\n",
    "df[\"ContractTime\"].fillna(\"nan\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = DictVectorizer()\n",
    "X_train_cat = enc.fit_transform(df[[\"LocationNormalized\", \"ContractTime\"]].to_dict(\"records\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = hstack([X_train_text, X_train_cat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Обучите гребневую регрессию с параметрами alpha=1 и random_state=241. Целевая переменная записана в столбце SalaryNormalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=241, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = df[\"SalaryNormalized\"]\n",
    "model = Ridge(alpha=1, random_state=241)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Постройте прогнозы для двух примеров из файла salary-test-mini.csv. Значения полученных прогнозов являются ответом на задание. Укажите их через пробел."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56555.62 37188.32\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv(\"salary-test-mini.csv\")\n",
    "\n",
    "X_test_text = vec.transform(text_transform(test[\"FullDescription\"]))\n",
    "X_test_cat = enc.transform(test[[\"LocationNormalized\", \"ContractTime\"]].to_dict(\"records\"))\n",
    "X_test = hstack([X_test_text, X_test_cat])\n",
    "\n",
    "y_test = model.predict(X_test)\n",
    "print(f\"{y_test[0]:.2f} {y_test[1]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
